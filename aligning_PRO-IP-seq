##############################
#                            #
#   PRO-IP-seq pipeline      #
#                            #
#       March 2023           #
#      viher@kth.se          #
#                            #
##############################

###############################################################################################################################################
# Separates reads from pooled samples using in-line barcode in R1. [barcode_splitter: https://gist.github.com/dgrtwo/3725741]
# Pairs R1-reads with their corresponding R2 [fastq_pair: https://github.com/linsalrob/fastq-pair]
# Generates fastqc files for visualising reads and their quality measures [fastqc: https://www.bioinformatics.babraham.ac.uk/projects/fastqc/]
# Trims the adapter sequences and lifts the UMI to the read title [fastp: https://github.com/OpenGene/fastp]
# Removes the barcodes and reverse complements R1. [fastx_toolkit: http://hannonlab.cshl.edu/fastx_toolkit/]
# Maps the reads, end-to-end to the human genome (sample genome). [bowtie2: https://github.com/BenLangmead/bowtie2]
# Maps reads that did not align to human genome to the mouse genome (spike-in genome). [bowtie2: https://github.com/BenLangmead/bowtie2]
# Collapses multimappers. [umi_tools: https://github.com/CGATOxford/UMI-tools]
# Sorts the reads. [samtools: https://github.com/samtools/samtools]
# Generates .bed and .bedgraph files [bedtools: https://bedtools.readthedocs.io/en/latest/]
# Generated .bigWig files. [bedGraphToBigWig: https://www.encodeproject.org/software/bedgraphtobigwig/]
###############################################################################################################################################

#######
# For description of PRO-IP-seq protocol and analyses, please see the original article:
# Vihervaara A, Versluis P, Himanen SV, Lis J. (2023). PRO-IP-seq Tracks Molecular Modifications of Engaged Pol II Complexes at Nucleotide Resolution. PMID:36778434.
# https://pubmed.ncbi.nlm.nih.gov/36778434/

#######
# For description of run-on-seq analyses and downstream processing, including identification of functional genomic regions, please see:
# Rabenius A, Chandrakumaran S, Sistonen L, Vihervaara A. (2022). Quantifying RNA synthesis at rate-limiting steps of transcription using nascent RNA-sequencing data. STAR Protoc. PMID: 35036951 
# https://www.sciencedirect.com/science/article/pii/S2666166721007425/pdf



###### Parameters ####
############################################################

UMI_LEN=7  # Length of UMI in basepairs ### we have 6nt +C (Decription of PRO-IP-seq, Vihervaara et al., 2023)

## Adaptor sequences to clip.
ADAPTOR_1="TGGAATTCTCGGGTGCCAAGGAACTCCAGTCAC"
ADAPTOR_2="GATCGTCGGACTGTAGAACTCTGAACGTGTAGATCTCGGTGGTCGCCGTATCATT"

## Update the paths to genome files as bt2:
genome_hg19="/PATH/genome_hg19_bt2/hg19"
genome_mm10="/PATH/genome_mm10_bt2/mm10" 

#in-lines barcodes. Generate text files that list the samples and which barcodes 
# Described in [barcode_splitter: https://gist.github.com/dgrtwo/3725741].
barcodes_NHS="Barcodes_NHS.txt"
barcodes_HS30="Barcodes_HS30.txt"

#=============================================================================================

mkdir -p logs
mkdir -p logs/fastqc
mkdir -p logs/fastp
mkdir -p duplicatesRemoved


#=============================================================================================
#### This first part takes the 3' indexed pools of samples and splits them into their own files.
# shown here for the NHS samples.

  gunzip NHS_R1.fastq.gz ### Pool of samples, Read 1
  gunzip NHS_R2.fastq.gz ### Pool of samples, Read 2
  
  cat NHS_R1.fastq | ${barcode_splitter} --bcfile ${barcodes_NHS} --bol --mismatches 2 --partial 2 --suffix "_BR1_R1.fastq"

  gzip NHS_R1.fastq


#=============================================================================================
### pairing the R1 and R2 for each NHS sample. R1 has been split. Here we query the pool of R2, matching each R2 to its corresponding R1.

List_file1="
NHS_CTD_BR1
NHS_S2_BR1
NHS_S5_BR1
NHS_S7_BR1
NHS_IgG_BR1
NHS_input_BR1
"

for x in ${List_file1}

do

   fastq_pair -p -t 50000000 ${x}_R1.fastq NHS_R2.fastq
   # pairing the reads after sample split. -t reflects the siz of the library, we had up to 50 M read pairs

  mv NHS_R2.fastq.paired.fq ${x}_R2_pa.fastq   ### renames the file, the next round would write over this.
  mv ${x}.fastq.paired.fq ${x}_R1_pa.fastq     ### renames the file for simplicity, matches the name for R2.
  rm *single*  #removes unpaired samples (you can also code the next query round to search from this file).

done

   gzip NHS_R2.fastq


#=============================================================================================
### pairing the R1 and R2 for each HS30 sample

  gunzip HS30_R1.fastq.gz ### Pool of HS30 samples, Read 1
  gunzip HS30_R2.fastq.gz ### Pool of HS30 samples, Read 2
  
  cat HS30_R1.fastq | ${barcode_splitter} --bcfile ${barcodes_HS30} --bol --mismatches 2 --partial 2 --suffix "_BR1_R1.fastq"

  gzip HS30_R1.fastq


List_file2="
HS30_CTD_BR1
HS30_S2_BR1
HS30_S5_BR1
HS30_S7_BR1
HS30_IgG_BR1
HS30_input_BR1
"



for x in ${List_file2}

do

    fastq_pair -p -t 500000000 ${x}.fastq HS30_R2.fastq
    #   pairing the reads after trimming. -t reflects the siz of the library, we had rougly 50 M read pairs

    mv HS30_R2.fastq.paired.fq ${x}_R2_pa.fastq     
    mv ${x}_R1.fastq.paired.fq ${x}_R1_pa.fastq     
    rm *single*

done

   gzip HS30_R2.fastq


#=============================================================================================
# Mapping the reads

List="
NHS_CTD_BR1
NHS_S2_BR1
NHS_S5_BR1
NHS_S7_BR1
NHS_IgG_BR1
NHS_input_BR1
HS30_CTD_BR1
HS30_S2_BR1
HS30_S5_BR1
HS30_S7_BR1
HS30_IgG_BR1
HS30_input_BR1
"


for x in ${List}

do

  ### analysing the read quality. Please note that also the in-line barcode and the presence of UMI (constant C at position 7) can be checked.
  
    fastqc ${x}_R1_pa.fastq -o logs/fastqc
    fastqc ${x}_R2_pa.fastq -o logs/fastqc
 
 
    fastp -i ${x}_R1_pa.fastq -I ${x}_R2_pa.fastq --out1 ${x}_R1_fp.fastq --out2 ${x}_R2_fp.fastq --adapter_sequence $ADAPTOR_1 --adapter_sequence_r2 $ADAPTOR_2 --umi --umi_loc=read2 --umi_len=${UMI_LEN} --html logs/fastp/${x}_fastp_log.html -w 10 --overlap_len_require 15 2> logs/fastp/${x}_fastp.log
    
    mv fastp.json ./logs/fastp/${x}_fastp.json
    fastqc ${x}_pair.fastq -o logs/fastqc

  
  ### removing the 3prime barcode.
  fastx_trimmer -f 8 -v -i ${x}_R1_fp.fastq -o ${x}_R1_trimmed.fastq -Q33  ### removes the 3prime barcode from Read 1.
  # The first nt to keep from the Read 1 is 8th (removes the 7 nt barcode).

  fastx_trimmer -t 7 -v -i ${x}_R2_fp.fastq -o ${x}_R2_trimmed.fastq -Q33  ### removes the 3prime barcode from Read 2.
  # Trims 7 nt from the end of Read 2. This removes the 7 nt barcode.
 
   
   ### reverse complements 
   echo making reverse complement of the clipped sequences of ${x}:
 
   fastx_reverse_complement -i ${x}_R1_trimmed.fastq -o ${x}_R1_q.fastq -Q33
  


    #########===============  e2e MAPPING TO hg19  ===========================================================
    
   ### Mapping to hg19 requiring e2e mapping 
   echo e2e aligning ${x} to hg19 with bowtie2:
   bowtie2 -p7 -q --end-to-end --ff -x ${genome_hg19} --un-conc ${x}_hgRemovedTemp.fastq -1 ${x}_R1_q.fastq -2 ${x}_R2_trimmed.fastq | awk '$2 != 4 {print}' | sed '/XS:/d' | samtools view -S -b '-' > ${x}_pair.bam
    
  
    #########===============  e2e MAPPING TO mm10 spikeIn genome  ===========================================================
    # Generating uniquely mapping reads to mm10. Aligning reeads that did not match to hg19 to avoid human sequences to match to spike-in.
    bowtie2 -p7 -q --end-to-end --ff -x ${genome_mm10} --un-conc ${x}_hgmmRemovedTemp.fastq -1 ${x}_hgRemovedTemp.1.fastq -2 ${x}_hgRemovedTemp.2.fastq | awk '$2 != 4 {print}' | sed '/XS:/d' | samtools view -S -b '-' > ${x}_uSpkInmm10.bam


    rm *Temp*


    #########===============  Collapsing based on genomic positions and UMIs  ===================

    umi_tools dedup --stdin ${x}_pair.bam --stdout ${x}_pair_deduped.bam --log ${x}_pair_umiTools_Log.log --umi-separator=":"

    umi_tools dedup --stdin ${x}_uSpkInmm10.bam --stdout ${x}_uSpkInmm10_deduped.bam --log ${x}_uSpkInmm10_umiTools_Log.log --umi-separator=":"
  
  
  
    #########============================  Bam and Bed files  ======================================
  
    samtools sort ${x}_pair_deduped.bam -o ${x}_pair_deduped_sorted.bam
    
    samtools index ${x}_pair_deduped_sorted.bam
    ## these set of commands create sorted and indexed bam file to be used in IGV.
    
    echo converting bam to bed file and sorting it:
    bamToBed -i ${x}_pair_deduped_sorted.bam | sort -k1,1 -k2,2n > ${x}_pair_sorted.bed

    echo converting spikeIn bam to bed file and sorting it:
    bamToBed -i ${x}_uSpkInmm10_deduped.bam | sort -k1,1 -k2,2n > ${x}_uSpkInmm10.bed


     #########=============== generating files for browsing etc. These are unnormalized. ===========================================================
  
    echo generating non-normalized bedgraph files of ${x}:
    awk '$6 == "+"' ${x}_pair_sorted.bed | genomeCoverageBed -i stdin -3 -bg -g ${chromSizes_hg19} > ${x}_pl.bedgraph
    awk '$6 == "-"' ${x}_pair_sorted.bed | genomeCoverageBed -i stdin -3 -bg -g ${chromSizes_hg19} > ${x}_m.bedgraph
    awk '{$4=$4*-1; print}' ${x}_m.bedgraph > ${x}_mn.bedgraph

    echo making bigwig from un-normalized bedgraph files of ${x}:
    ${bgTObigWig} ${x}_pl.bedgraph ${chromSizes_hg19} ${x}_pl.bigWig
    ${bgTObigWig} ${x}_mn.bedgraph ${chromSizes_hg19} ${x}_mn.bigWig
  
  
    c=$(grep -c ^ ${x}_pair_sorted.bed)

    echo total count from sorted.bed file of ${x} is:
    echo $c

    echo $c | awk '{ c="'$c'"; printf "%s\t%s\t%s\t%s\n", $1, $2, $3, ($4*1000000)/c}' ${x}_pl.bedgraph  > ${x}_RPMnorm_pl.bedgraph
    echo $c | awk '{ c="'$c'"; printf "%s\t%s\t%s\t%s\n", $1, $2, $3, ($4*1000000)/c}' ${x}_mn.bedgraph  > ${x}_RPMnorm_mn.bedgraph
    ## generates sequnecing depth (RPM) normalized bedgraph files by dividing the fourth column of bedgraph file with total number of mapped reads and multiplying the resulting number with 1M (RPM - Reads Per Million)

    echo making bigwig from RPM normalized bedgraph files of ${x}:
    ${bgTObigWig} ${x}_RPMnorm_pl.bedgraph ${chromSizes_hg19} ${x}_RPMnorm_pl.bigWig
    ${bgTObigWig} ${x}_RPMnorm_mn.bedgraph ${chromSizes_hg19} ${x}_RPMnorm_mn.bigWig




#############################

    
    
  done
    
